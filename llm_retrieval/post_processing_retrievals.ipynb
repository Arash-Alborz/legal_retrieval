{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "281013a5",
   "metadata": {},
   "source": [
    "### Post processing text output of ID retrievals (gpt, llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e0bc7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_nl.json written to: retrievals/json/qwen3-235B_id_retrieval_nl.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Script for post processing gpt and llama ID retrievals...\n",
    "It takes text files and converts them to json files for evaluation.\n",
    "\n",
    "'''\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "results_txt = Path(\"retrievals/txt/qwen3-235B_id_retrieval_nl.txt\") # change name of the file [llama3.3.70b_id_retrieval_{lang}.txt], [gpt4.1.mini_pw_retrievals_nl.txt], [qwen3-235B_id_retrieval_nl.txt]\n",
    "output_json = Path(\"retrievals/json/qwen3-235B_id_retrieval_nl.json\") # output\n",
    "\n",
    "pattern_query = re.compile(r\"^query id:\\s*(\\d+)\")\n",
    "pattern_relevant = re.compile(r\"^relevant articles:\\s*(.*)\")\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "with open(results_txt, encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "i = 0\n",
    "while i < len(lines) - 1:\n",
    "    m_query = pattern_query.match(lines[i])\n",
    "    m_relevant = pattern_relevant.match(lines[i+1])\n",
    "    if m_query and m_relevant:\n",
    "        qid = m_query.group(1)\n",
    "        relevant_articles = [x.strip() for x in m_relevant.group(1).split(\",\") if x.strip()]\n",
    "        results_dict[qid] = relevant_articles\n",
    "        i += 2\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as out:\n",
    "    json.dump(results_dict, out, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"results_nl.json written to: {output_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d0a8c",
   "metadata": {},
   "source": [
    "### Post processing gpt binary-classification retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3a275681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rewritten to proper JSONL with string-normalized relevance. Total entries: 53\n",
      "ðŸ“„ Saved to: retrievals/qwen3.235b_bin_class_retrieval_nl_fixed.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_path = \"retrievals/qwen3.235b_bin_class_retrieval_nl.jsonl\"\n",
    "output_path = \"retrievals/qwen3.235b_bin_class_retrieval_nl_fixed.jsonl\"\n",
    "\n",
    "buffer = \"\"\n",
    "results = []\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        buffer += line\n",
    "        if line.strip().endswith(\"}\"):  # crude heuristic: object may be complete\n",
    "            try:\n",
    "                obj = json.loads(buffer)\n",
    "\n",
    "                # --- Normalize relevance field ---\n",
    "                if \"relevance\" in obj and isinstance(obj[\"relevance\"], dict):\n",
    "                    normalized_relevance = {}\n",
    "                    for k, v in obj[\"relevance\"].items():\n",
    "                        # Convert both keys and values to strings\n",
    "                        str_k = str(k)\n",
    "                        str_v = str(v) if v in [0, 1, \"0\", \"1\"] else \"?\"\n",
    "                        normalized_relevance[str_k] = str_v\n",
    "                    obj[\"relevance\"] = normalized_relevance\n",
    "\n",
    "                results.append(obj)\n",
    "                buffer = \"\"\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # wait for more lines\n",
    "\n",
    "# Write clean JSONL\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for obj in results:\n",
    "        json_line = json.dumps(obj, ensure_ascii=False)\n",
    "        out_f.write(json_line + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Rewritten to proper JSONL with string-normalized relevance. Total entries: {len(results)}\")\n",
    "print(f\"ðŸ“„ Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6212d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "Total queries processed: 53\n",
      "Fully correct queries: 53\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Script for checking the LLM output. It checks if LLM changes or added or removed any article ids --> comparing to all hard negatives.\n",
    "It also checks the values if they are only 0 or 1. No other characters or empty values. FOR GPT output...\n",
    "\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "gpt_output_path = \"retrievals/qwen3.235b_bin_class_retrieval_nl_fixed.jsonl\"\n",
    "hard_negatives_path = \"../sampling_hard_negatives/hard_negatives/hard_negatives_nl.jsonl\"\n",
    "\n",
    "# load hard negatives\n",
    "hard_negatives = {}\n",
    "with open(hard_negatives_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        hard_negatives[entry[\"query_id\"]] = set(entry[\"candidate_docs\"])\n",
    "\n",
    "invalid_values_queries = []\n",
    "missing_ids_queries = {}\n",
    "extra_ids_queries = {}\n",
    "valid_queries = []\n",
    "\n",
    "with open(gpt_output_path, encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f, 1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Line {idx}: INVALID JSON\")\n",
    "            continue\n",
    "\n",
    "        query_id = obj.get(\"query_id\")\n",
    "        relevance = obj.get(\"relevance\", {})\n",
    "\n",
    "        # check relevance values\n",
    "        invalid_values = [v for v in relevance.values() if v not in (\"0\", \"1\")]\n",
    "        if invalid_values:\n",
    "            invalid_values_queries.append(query_id)\n",
    "\n",
    "        # check candidate IDs\n",
    "        expected_ids = hard_negatives.get(query_id)\n",
    "        if not expected_ids:\n",
    "            continue\n",
    "\n",
    "        actual_ids = set(relevance.keys())\n",
    "\n",
    "        missing = expected_ids - actual_ids\n",
    "        extra = actual_ids - expected_ids\n",
    "\n",
    "        if missing:\n",
    "            missing_ids_queries[query_id] = missing\n",
    "        if extra:\n",
    "            extra_ids_queries[query_id] = extra\n",
    "        if not invalid_values and not missing and not extra:\n",
    "            valid_queries.append(query_id)\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total queries processed: {len(valid_queries) + len(invalid_values_queries) + len(missing_ids_queries) + len(extra_ids_queries)}\")\n",
    "print(f\"Fully correct queries: {len(valid_queries)}\")\n",
    "\n",
    "if invalid_values_queries:\n",
    "    print(f\"\\nQueries with invalid relevance values: {invalid_values_queries}\")\n",
    "if missing_ids_queries:\n",
    "    print(\"\\nQueries with missing article IDs:\")\n",
    "    for qid, ids in missing_ids_queries.items():\n",
    "        print(f\"  Query {qid}: Missing IDs: {ids}\")\n",
    "if extra_ids_queries:\n",
    "    print(\"\\nQueries with extra article IDs:\")\n",
    "    for qid, ids in extra_ids_queries.items():\n",
    "        print(f\"  Query {qid}: Extra IDs: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "917656c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ">>> Script for post ptocessing the binary classification (0/1) outputs and convert them to json retrievals. Only getting the 1 values --> relevant articles. \n",
    "\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "input_path = \"retrievals/xtra/qwen3.235b_bin_class_retrieval_nl.jsonl\"\n",
    "output_path = \"retrievals/json/qwen3.235b_bin_class_retrieval_nl.json\"\n",
    "\n",
    "result = {}\n",
    "\n",
    "with open(input_path, encoding=\"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        query_id = obj[\"query_id\"]\n",
    "        relevance = obj[\"relevance\"]\n",
    "\n",
    "        relevant_articles = [aid for aid, val in relevance.items() if val == \"1\"]\n",
    "        result[query_id] = relevant_articles\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    json.dump(result, fout, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668091b5",
   "metadata": {},
   "source": [
    "### checking all retrievals, if all queries are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "590fb118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gold queries: 203\n",
      "Total predicted queries: 203\n",
      "\n",
      "All gold query IDs are present in predictions.\n",
      "No extra query IDs in predictions.\n",
      "\n",
      "Predictions file matches gold file perfectly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths â€” adjust if needed\n",
    "#predictions_json = Path(\"retrievals/json/gemini_2.5_flash_id_retrieval_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gpt4.1.mini_id_retrievals_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gpt4o.mini_id_retrievals_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gpt4.1.mini_bin_class_retrievals_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gpt4o.mini_bin_class_retrievals_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gemini_2.5_flash_pro_id_retrieval_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gemini_2.5.flash_bin_class_retrieval_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/gemini_2.5.pro_id_retrieval_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/llama3.3.70b_id_retrieval_nl.json\")\n",
    "#predictions_json = Path(\"retrievals/json/llama3.3.70b_bin_class_retrieval_nl.json\")\n",
    "predictions_json = Path(\"retrievals/json/qwen3.235b_bin_class_retrieval_nl.json\")\n",
    "\n",
    "gold_json = Path(\"gold_data/gold_standard_nl.json\")\n",
    "\n",
    "# Load predictions\n",
    "with open(predictions_json, encoding=\"utf-8\") as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "# Load gold\n",
    "with open(gold_json, encoding=\"utf-8\") as f:\n",
    "    gold = json.load(f)\n",
    "\n",
    "pred_ids = set(predictions.keys())\n",
    "gold_ids = set(gold.keys())\n",
    "\n",
    "missing_in_preds = gold_ids - pred_ids\n",
    "extra_in_preds = pred_ids - gold_ids\n",
    "\n",
    "print(f\"Total gold queries: {len(gold_ids)}\")\n",
    "print(f\"Total predicted queries: {len(pred_ids)}\\n\")\n",
    "\n",
    "if missing_in_preds:\n",
    "    print(f\"Missing in predictions ({len(missing_in_preds)}):\")\n",
    "    for qid in sorted(missing_in_preds):\n",
    "        print(f\"  {qid}\")\n",
    "else:\n",
    "    print(\"All gold query IDs are present in predictions.\")\n",
    "\n",
    "if extra_in_preds:\n",
    "    print(f\"\\nExtra query IDs in predictions ({len(extra_in_preds)}):\")\n",
    "    for qid in sorted(extra_in_preds):\n",
    "        print(f\"  {qid}\")\n",
    "else:\n",
    "    print(\"No extra query IDs in predictions.\")\n",
    "\n",
    "if not missing_in_preds and not extra_in_preds:\n",
    "    print(\"\\nPredictions file matches gold file perfectly.\")\n",
    "else:\n",
    "    print(\"\\nPlease fix mismatches before evaluating.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd00e41",
   "metadata": {},
   "source": [
    "### Checking the output of rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f61a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------- CONFIG --------\n",
    "lang = \"nl\"  # or 'fr'\n",
    "output_file_path = Path(f\"rankings/gemini2.5.flash_sorted_ranking_{lang}.txt\") # gemini2.5.flash_sorted_ranking_{lang}.txt # gpt4o.mini_sorted_ranking_{lang}\n",
    "#output_file_path = Path(f\"rankings/gpt4.1.mini_sorted_ranking_{lang}.txt\")\n",
    "hard_negatives_path = Path(f\"../sampling_hard_negatives/hard_negatives/hard_negatives_{lang}.jsonl\")\n",
    "\n",
    "# -------- LOAD HARD NEGATIVE SET --------\n",
    "with open(hard_negatives_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    hard_data = [json.loads(line) for line in f]\n",
    "\n",
    "query_to_candidates = {\n",
    "    entry[\"query_id\"]: set(entry[\"candidate_docs\"])\n",
    "    for entry in hard_data\n",
    "}\n",
    "\n",
    "# -------- PARSE MODEL OUTPUT --------\n",
    "with open(output_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "report = []\n",
    "for i in range(0, len(lines), 2):\n",
    "    qid_line = lines[i].strip()\n",
    "    result_line = lines[i + 1].strip() if i + 1 < len(lines) else \"\"\n",
    "\n",
    "    if not (qid_line.startswith(\"query id:\") and result_line.startswith(\"ranked articles:\")):\n",
    "        continue\n",
    "\n",
    "    qid = qid_line.split(\":\", 1)[1].strip()\n",
    "    ids_str = result_line.split(\":\", 1)[1].strip()\n",
    "    predicted_ids = [x.strip() for x in ids_str.split(\",\") if x.strip()]\n",
    "    predicted_set = set(predicted_ids)\n",
    "\n",
    "    candidate_set = query_to_candidates.get(qid, set())\n",
    "\n",
    "    hallucinated_ids = sorted(predicted_set - candidate_set)\n",
    "    missing_ids = sorted(candidate_set - predicted_set)\n",
    "\n",
    "    report.append({\n",
    "        \"query_id\": qid,\n",
    "        \"n_predicted\": len(predicted_ids),\n",
    "        \"n_candidates\": len(candidate_set),\n",
    "        \"n_hallucinated\": len(hallucinated_ids),\n",
    "        \"hallucinated_ids\": hallucinated_ids,\n",
    "        \"n_missing\": len(missing_ids),\n",
    "        \"missing_ids\": missing_ids\n",
    "    })\n",
    "\n",
    "# -------- PRINT REPORT --------\n",
    "for entry in report:\n",
    "    if entry[\"n_hallucinated\"] > 0:\n",
    "        print(f\"Query {entry['query_id']}:\")\n",
    "        print(f\"  Predicted {entry['n_predicted']} articles.\")\n",
    "        print(f\"  Hallucinated IDs: {entry['hallucinated_ids']}\")\n",
    "        print(f\"  Missing IDs: {entry['missing_ids']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428855a",
   "metadata": {},
   "source": [
    "## chacking and post-processing the scored_ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe65065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating and sorting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:00<00:00, 29915.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping query 7: mismatched article IDs.\n",
      "Skipping query 178: mismatched article IDs.\n",
      "Skipping query 274: mismatched article IDs.\n",
      "\n",
      "Fixed and validated output written to: rankings/scored/llama4.scout_score_ranking_nl_sorted.jsonl\n",
      "Ranks-only output written to: rankings/scored/llama4.scout.ranks.nl.jsonl\n",
      "\n",
      "âš  Missing query IDs (9):\n",
      "['1002', '101', '171', '178', '228', '274', '69', '7', '93']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "output_path = Path(f\"rankings/scored/llama4.scout_naghes_score_ranking_nl.jsonl\")\n",
    "hard_negatives_path = Path(f\"../sampling_hard_negatives/hard_negatives/hard_negatives_nl.jsonl\")\n",
    "fixed_output_path = Path(f\"rankings/scored/llama4.scout_score_ranking_nl_sorted.jsonl\")\n",
    "\n",
    "\n",
    "# === LOAD HARD NEGATIVES (GROUND TRUTH) ===\n",
    "with open(hard_negatives_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    hard_negatives = [json.loads(line) for line in f]\n",
    "\n",
    "expected_query_ids = set()\n",
    "expected_doc_ids_per_query = {}\n",
    "\n",
    "for entry in hard_negatives:\n",
    "    qid = str(entry[\"query_id\"])\n",
    "    expected_query_ids.add(qid)\n",
    "    expected_doc_ids_per_query[qid] = set(entry[\"candidate_docs\"])\n",
    "\n",
    "\n",
    "# === READ AND FIX MALFORMED JSONL ===\n",
    "fixed_entries = []\n",
    "current_entry_lines = []\n",
    "\n",
    "with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.startswith('{') and current_entry_lines:\n",
    "            try:\n",
    "                entry = json.loads(' '.join(current_entry_lines))\n",
    "                fixed_entries.append(entry)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Skipping malformed entry.\")\n",
    "            current_entry_lines = [line]\n",
    "        else:\n",
    "            current_entry_lines.append(line)\n",
    "\n",
    "    # Process last entry\n",
    "    if current_entry_lines:\n",
    "        try:\n",
    "            entry = json.loads(' '.join(current_entry_lines))\n",
    "            fixed_entries.append(entry)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Skipping final malformed entry.\")\n",
    "\n",
    "\n",
    "# === SORT AND VALIDATE ===\n",
    "valid_entries = []\n",
    "\n",
    "for entry in tqdm(fixed_entries, desc=\"Validating and sorting\"):\n",
    "    qid = entry.get(\"query_id\")\n",
    "    scores = entry.get(\"relevance_scores\", {})\n",
    "    if not qid or qid not in expected_query_ids:\n",
    "        print(f\"Skipping unknown or missing query ID: {qid}\")\n",
    "        continue\n",
    "\n",
    "    if set(scores.keys()) != expected_doc_ids_per_query[qid]:\n",
    "        print(f\"Skipping query {qid}: mismatched article IDs.\")\n",
    "        continue\n",
    "\n",
    "    # Sort by score descending\n",
    "        # Convert all scores to integers (handle str/int mix)\n",
    "    try:\n",
    "        int_scores = {doc_id: int(score) for doc_id, score in scores.items()}\n",
    "    except ValueError:\n",
    "        print(f\"Skipping query {qid}: contains non-integer-convertible score.\")\n",
    "        continue\n",
    "\n",
    "    # Sort by descending score\n",
    "    sorted_scores = dict(sorted(int_scores.items(), key=lambda x: -x[1]))\n",
    "    valid_entries.append({\n",
    "        \"query_id\": qid,\n",
    "        \"relevance_scores\": sorted_scores\n",
    "    })\n",
    "\n",
    "\n",
    "# === WRITE FIXED JSONL ===\n",
    "fixed_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(fixed_output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for entry in valid_entries:\n",
    "        f_out.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"\\nFixed and validated output written to: {fixed_output_path}\")\n",
    "\n",
    "# === WRITE SECOND OUTPUT (ONLY RANKED DOC IDS, NO SCORES) ===\n",
    "ranks_only_output_path = Path(\"rankings/scored/llama4.scout.ranks.nl.jsonl\")\n",
    "\n",
    "with open(ranks_only_output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for entry in valid_entries:\n",
    "        qid = entry[\"query_id\"]\n",
    "        ranked_ids = list(entry[\"relevance_scores\"].keys())  # Already sorted\n",
    "        f_out.write(json.dumps({\n",
    "            \"query_id\": qid,\n",
    "            \"ranks\": ranked_ids\n",
    "        }) + \"\\n\")\n",
    "\n",
    "print(f\"Ranks-only output written to: {ranks_only_output_path}\")\n",
    "\n",
    "# === REPORT MISSING QUERIES ===\n",
    "fixed_query_ids = {entry[\"query_id\"] for entry in valid_entries}\n",
    "missing_query_ids = sorted(expected_query_ids - fixed_query_ids)\n",
    "\n",
    "if missing_query_ids:\n",
    "    print(f\"\\nâš  Missing query IDs ({len(missing_query_ids)}):\")\n",
    "    print(missing_query_ids)\n",
    "else:\n",
    "    print(\"\\nAll query IDs accounted for.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_legal_document_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
