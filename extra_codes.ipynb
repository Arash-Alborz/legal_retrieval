{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0f7e6f",
   "metadata": {},
   "source": [
    "## Dutch article cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def clean_article_start(text):\n",
    "    # removing tokens in the start of the  article\n",
    "    text = re.sub(r\"^(Art\\.?|Artikel|ANNEXE|DROIT FUTUR|Antérieurement|Voir note sous TITRE|BIJLAGE|Inbreuk op artikel|Voorheen)\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # removing numbers, dots, non-words\n",
    "    text = re.sub(r\"^\\d+[^\\w]*\\s*\", \"\", text)\n",
    "\n",
    "    # list of common words in the beginning\n",
    "    forbidden_words = [\"Art\", \"Artikel\", \"ANNEXE\", \"DROIT FUTUR\", \"Antérieurement\", \"Voir note sous TITRE\", \"BIJLAGE\", \"Inbreuk op artikel\", \"Voorheen\"]\n",
    "\n",
    "    # scanning for capital letter\n",
    "    for match in re.finditer(r\"[A-Z]\", text):\n",
    "        start_index = match.start()\n",
    "\n",
    "        # excluding capital letter if inside a common word\n",
    "        window_start = max(0, start_index - 10)\n",
    "        window_text = text[window_start:start_index + 10]\n",
    "\n",
    "        if any(forbidden.lower() in window_text.lower() for forbidden in forbidden_words):\n",
    "            continue\n",
    "\n",
    "        # checking next two characters after capital letter\n",
    "        next_chars = text[start_index+1:start_index+3]\n",
    "        if not re.match(r\"[\\s*'a-zA-Z]{1,2}\", next_chars):\n",
    "            continue\n",
    "\n",
    "        return text[start_index:].strip()\n",
    "\n",
    "    # If nothing found → return original text\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# ---> REMOVING LONG ARTICLES BEFORE CLEANING <--- Can take the next 3 lines of code out when working with the whole corpus\n",
    "with open(\"long_article_ids.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    long_article_ids = json.load(f)\n",
    "\n",
    "df_corpus_nl = df_corpus_nl[~df_corpus_nl[\"id\"].isin(long_article_ids)]\n",
    "\n",
    "# apply cleaning\n",
    "df_corpus_nl[\"article_cleaned\"] = df_corpus_nl[\"article\"].apply(clean_article_start)\n",
    "\n",
    "# making two directories for cleaned corpus and mixed corpus for comparison\n",
    "os.makedirs(\"data/original_cleaned_mix_corpus\", exist_ok=True)\n",
    "os.makedirs(\"data/cleaned_corpus\", exist_ok=True)\n",
    "\n",
    "df_corpus_nl.to_csv(\"data/original_cleaned_mix_corpus/original_cleaned_mix_nl_corpus.csv\", index=False)\n",
    "\n",
    "\n",
    "df_corpus_nl_original_format = df_corpus_nl[[\"id\", \"reference\", \"article_cleaned\"]].rename(columns={\"article_cleaned\": \"article\"})\n",
    "df_corpus_nl_original_format.to_csv(\"data/cleaned_corpus/corpus_nl_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Created a mixed CSV of original and cleaned Dutch article texts for comparison.\")\n",
    "\n",
    "print(\"Saved cleaned Dutch corpus as CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c84d1",
   "metadata": {},
   "source": [
    "## French article cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def clean_article_start(text):\n",
    "    # removing tokens in the start of the  article\n",
    "    text = re.sub(r\"[\\(\\[]\\s*(ancien article|ancien art|erronément intitulé art\\.?)\\s*\\d+[^\\]\\)]*[\\)\\]]\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"^(Art\\.?|Article|ANNEXE|DROIT FUTUR|Antérieurement|Voir note sous TITRE|ancien article|Infraction à l'article)\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # removing numbers, dots, non-words\n",
    "    text = re.sub(r\"^\\d+[^\\w]*\\s*\", \"\", text)\n",
    "\n",
    "    # list of common words in the beginning\n",
    "    forbidden_words = [\"Art\", \"Article\", \"ANNEXE\", \"DROIT FUTUR\", \"Antérieurement\", \"Voir note sous TITRE\", \"ancien article\", \"Infraction à l'article\"]\n",
    "\n",
    "    # scanning for capital letter\n",
    "    for match in re.finditer(r\"[A-Z]\", text):\n",
    "        start_index = match.start()\n",
    "\n",
    "        # excluding capital letter if inside a common word\n",
    "        window_start = max(0, start_index - 10)\n",
    "        window_text = text[window_start:start_index + 10]\n",
    "\n",
    "        if any(forbidden.lower() in window_text.lower() for forbidden in forbidden_words):\n",
    "            continue\n",
    "\n",
    "        # checking next two characters after capital letter\n",
    "        next_chars = text[start_index+1:start_index+3]\n",
    "        if not re.match(r\"[\\s*'a-zA-Z]{1,2}\", next_chars):\n",
    "            continue\n",
    "\n",
    "        return text[start_index:].strip()\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# ---> REMOVING LONG ARTICLES BEFORE CLEANING <--- Can take the next 3 lines of code out when working with the whole corpus\n",
    "with open(\"long_article_ids.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    long_article_ids = json.load(f)\n",
    "\n",
    "df_corpus_fr = df_corpus_fr[~df_corpus_fr[\"id\"].isin(long_article_ids)]\n",
    "# apply cleaning\n",
    "df_corpus_fr[\"article_cleaned\"] = df_corpus_fr[\"article\"].apply(clean_article_start)\n",
    "\n",
    "# making two directories for cleaned corpus and mixed corpus for comparison\n",
    "os.makedirs(\"data/original_cleaned_mix_corpus\", exist_ok=True)\n",
    "os.makedirs(\"data/cleaned_corpus\", exist_ok=True)\n",
    "\n",
    "df_corpus_fr.to_csv(\"data/original_cleaned_mix_corpus/original_cleaned_mix_fr_corpus.csv\", index=False)\n",
    "\n",
    "df_corpus_fr_original_format = df_corpus_fr[[\"id\", \"reference\", \"article_cleaned\"]].rename(columns={\"article_cleaned\": \"article\"})\n",
    "df_corpus_fr_original_format.to_csv(\"data/cleaned_corpus/corpus_fr_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Created a mixed CSV of original and cleaned French article texts for comparison.\")\n",
    "print(\"Saved cleaned French corpus as CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2414f13",
   "metadata": {},
   "source": [
    "## SAMPLING CODES (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82922ec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bm25_hard_negatives_fr.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m jsonl_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbm25_hard_negatives_fr.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read and print contents\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjsonl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m         item \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_legal_document_retrieval/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bm25_hard_negatives_fr.jsonl'"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "corpus = load_from_disk(\"/content/data/cleaned/corpus\")\n",
    "test = load_from_disk(\"/content/data/cleaned/test\")\n",
    "\n",
    "corpus_fr = corpus['fr']\n",
    "test_fr = test['fr']\n",
    "\n",
    "\n",
    "### WITH SCORES AND RANKS FOR FRENCH\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "# Load cleaned corpus and test queries (French as example)\n",
    "corpus = load_from_disk(\"data/cleaned/corpus\")['fr']\n",
    "test_queries = load_from_disk(\"data/cleaned/test\")['fr']\n",
    "\n",
    "# Prepare corpus documents and their IDs\n",
    "corpus_docs = [doc['article'] for doc in corpus]\n",
    "corpus_ids = [str(doc['id']) for doc in corpus]\n",
    "\n",
    "# Tokenize corpus with ToktokTokenizer\n",
    "tokenized_corpus = [tokenizer.tokenize(doc.lower()) for doc in corpus_docs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Prepare output\n",
    "output = []\n",
    "\n",
    "for query in tqdm(test_queries):\n",
    "\n",
    "    query_id = query['id']\n",
    "    query_text = query['question']\n",
    "    \n",
    "    # Get relevant article IDs for this query\n",
    "    relevant_ids = [id_.strip() for id_ in query['article_ids'].split(\",\") if id_.strip() != \"\"]\n",
    "    num_relevant = len(relevant_ids)\n",
    "    \n",
    "    # Calculate how many negatives needed\n",
    "    num_negatives_needed = 100 - num_relevant\n",
    "    \n",
    "    # Tokenize query text using ToktokTokenizer\n",
    "    tokenized_query = tokenizer.tokenize(query_text.lower())\n",
    "\n",
    "    # BM25 scoring\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Combine document ID, score and index\n",
    "    scored_docs = [\n",
    "        {\"doc_id\": corpus_ids[idx], \"score\": float(bm25_scores[idx]), \"rank\": None}\n",
    "        for idx in range(len(bm25_scores))\n",
    "    ]\n",
    "    \n",
    "    # Sort by score (high to low) → rank them properly\n",
    "    scored_docs = sorted(scored_docs, key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    # Add final rank after sorting (rank 0 = highest score)\n",
    "    for final_rank, doc in enumerate(scored_docs):\n",
    "        doc[\"rank\"] = final_rank + 1  # make ranks 1-based\n",
    "\n",
    "    # Select negatives (skip relevant ids)\n",
    "    hard_negatives = []\n",
    "    \n",
    "    for doc in scored_docs:\n",
    "        if doc[\"doc_id\"] not in relevant_ids:\n",
    "            hard_negatives.append(doc)\n",
    "        if len(hard_negatives) >= num_negatives_needed:\n",
    "            break\n",
    "\n",
    "    # Save full ranked list + hard negatives\n",
    "    output.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"query_text\": query_text,\n",
    "        \"relevant_ids\": relevant_ids,\n",
    "        \"bm25_ranked_list\": scored_docs,  # FULL ranked list with doc_id, score, rank\n",
    "        \"hard_negatives\": hard_negatives  # selected hard negatives only\n",
    "    })\n",
    "\n",
    "# Save to JSONL\n",
    "os.makedirs(\"data/bm25_sampling\", exist_ok=True)\n",
    "output_path = \"data/bm25_sampling/bm25_with_scores_and_ranks_fr.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in output:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "#print(\"✅ BM25 sampling complete and saved (with scores and ranks).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c527e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WITH SCORES AND RANKS FOR DUTCH\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "# Load cleaned corpus and test queries (Dutch)\n",
    "corpus = load_from_disk(\"data/cleaned/corpus\")['nl']\n",
    "test_queries = load_from_disk(\"data/cleaned/test\")['nl']\n",
    "\n",
    "# Prepare corpus documents and their IDs\n",
    "corpus_docs = [doc['article'] for doc in corpus]\n",
    "corpus_ids = [str(doc['id']) for doc in corpus]\n",
    "\n",
    "# Tokenize corpus with ToktokTokenizer\n",
    "tokenized_corpus = [tokenizer.tokenize(doc.lower()) for doc in corpus_docs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Prepare output\n",
    "output = []\n",
    "\n",
    "for query in tqdm(test_queries):\n",
    "\n",
    "    query_id = query['id']\n",
    "    query_text = query['question']\n",
    "    \n",
    "    # Get relevant article IDs for this query\n",
    "    relevant_ids = [id_.strip() for id_ in query['article_ids'].split(\",\") if id_.strip() != \"\"]\n",
    "    num_relevant = len(relevant_ids)\n",
    "    \n",
    "    # Calculate how many negatives needed\n",
    "    num_negatives_needed = 100 - num_relevant\n",
    "    \n",
    "    # Tokenize query text using ToktokTokenizer\n",
    "    tokenized_query = tokenizer.tokenize(query_text.lower())\n",
    "\n",
    "    # BM25 scoring\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Combine document ID, score and index\n",
    "    scored_docs = [\n",
    "        {\"doc_id\": corpus_ids[idx], \"score\": float(bm25_scores[idx]), \"rank\": None}\n",
    "        for idx in range(len(bm25_scores))\n",
    "    ]\n",
    "    \n",
    "    # Sort by score (high to low) → rank them properly\n",
    "    scored_docs = sorted(scored_docs, key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    # Add final rank after sorting (rank 0 = highest score)\n",
    "    for final_rank, doc in enumerate(scored_docs):\n",
    "        doc[\"rank\"] = final_rank + 1  # make ranks 1-based\n",
    "\n",
    "    # Select negatives (skip relevant ids)\n",
    "    hard_negatives = []\n",
    "    \n",
    "    for doc in scored_docs:\n",
    "        if doc[\"doc_id\"] not in relevant_ids:\n",
    "            hard_negatives.append(doc)\n",
    "        if len(hard_negatives) >= num_negatives_needed:\n",
    "            break\n",
    "\n",
    "    # Save full ranked list + hard negatives\n",
    "    output.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"query_text\": query_text,\n",
    "        \"relevant_ids\": relevant_ids,\n",
    "        \"bm25_ranked_list\": scored_docs,  # FULL ranked list with doc_id, score, rank\n",
    "        \"hard_negatives\": hard_negatives  # selected hard negatives only\n",
    "    })\n",
    "\n",
    "# Save to JSONL\n",
    "os.makedirs(\"data/bm25_sampling\", exist_ok=True)\n",
    "output_path = \"data/bm25_sampling/bm25_with_scores_and_ranks_nl.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in output:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"BM25 sampling complete and saved (with scores and ranks) for DUTCH.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a687fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR LOADING AND CHECKING\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# Load French BM25 results\n",
    "fr_path = \"data/bm25_sampling/bm25_with_scores_and_ranks_fr.jsonl\"\n",
    "with open(fr_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    french_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"✅ Loaded {len(french_data)} French BM25 entries\")\n",
    "print(\"Example:\")\n",
    "print(french_data[:5])  # Show first entry\n",
    "\n",
    "# Load Dutch BM25 results\n",
    "nl_path = \"data/bm25_sampling/bm25_hard_negatives_nl.jsonl\"\n",
    "with open(nl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dutch_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(dutch_data)} Dutch BM25 entries\")\n",
    "print(\"Example:\")\n",
    "print(dutch_data[5])  # Show first entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0504169",
   "metadata": {},
   "source": [
    "## The following code is for removing all the relevant article ids from the data. It can be used but I will not use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning and saving as CSV and dataset.arrows\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "ds_test = load_dataset(\"clips/bBSARD\", \"test\")\n",
    "test_fr = ds_test[\"fr\"]\n",
    "test_nl = ds_test[\"nl\"]\n",
    "\n",
    "# Load long article citation map\n",
    "with open(\"queries_citing_long_articles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    queries_citing_long_articles = json.load(f)\n",
    "\n",
    "long_articles_fr = queries_citing_long_articles[\"fr\"]\n",
    "long_articles_nl = queries_citing_long_articles[\"nl\"]\n",
    "\n",
    "# Cleaning function\n",
    "def clean_query_set(test_set, long_article_map, lang_label):\n",
    "    cleaned = []\n",
    "    for query in test_set:\n",
    "        query_id = str(query[\"id\"])\n",
    "        relevant_ids = [id_.strip() for id_ in query[\"article_ids\"].split(\",\")]\n",
    "\n",
    "        if len(relevant_ids) > 10:\n",
    "            continue\n",
    "\n",
    "        if query_id in long_article_map:\n",
    "            long_ids = set(long_article_map[query_id])\n",
    "            relevant_ids = [id_ for id_ in relevant_ids if id_ not in long_ids]\n",
    "\n",
    "        if len(relevant_ids) == 0:\n",
    "            continue\n",
    "\n",
    "        query_cleaned = dict(query)\n",
    "        query_cleaned[\"article_ids\"] = \", \".join(relevant_ids)\n",
    "        cleaned.append(query_cleaned)\n",
    "    print(f\"Cleaned {len(cleaned)} {lang_label} queries.\")\n",
    "    return cleaned\n",
    "\n",
    "cleaned_fr = clean_query_set(test_fr, long_articles_fr, \"French\")\n",
    "cleaned_nl = clean_query_set(test_nl, long_articles_nl, \"Dutch\")\n",
    "\n",
    "os.makedirs(\"data/cleaned_queries_csv\", exist_ok=True)\n",
    "pd.DataFrame(cleaned_fr).to_csv(\"data/cleaned_queries_csv/cleaned_test_queries_fr.csv\", index=False)\n",
    "pd.DataFrame(cleaned_nl).to_csv(\"data/cleaned_queries_csv/cleaned_test_queries_nl.csv\", index=False)\n",
    "\n",
    "ds_cleaned_fr = Dataset.from_list(cleaned_fr)\n",
    "ds_cleaned_nl = Dataset.from_list(cleaned_nl)\n",
    "\n",
    "ds_cleaned = DatasetDict({\n",
    "    \"fr\": ds_cleaned_fr,\n",
    "    \"nl\": ds_cleaned_nl\n",
    "})\n",
    "os.makedirs(\"data/cleaned_queries_ds\", exist_ok=True)\n",
    "ds_cleaned.save_to_disk(\"data/cleaned_queries_ds/cleaned_test_queries\")\n",
    "print(\"Saved cleaned test queries to HuggingFace dataset format.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_legal_document_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
