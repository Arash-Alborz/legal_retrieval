{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec45baa1",
   "metadata": {},
   "source": [
    "## Building the hard negatives\n",
    "The following scripts get 100 BM25 ranks and look for missing articles in the ranks. If relevant articles are missing from the 100 ranks for each query,\n",
    "then it drops lower ranks and injects relevant article ids into the lists. \n",
    "--> All the hard negatives have exactly 100 articles including the highest Bm25 ranks and relevant articles from the gold data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b46afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ">>> Script for extracting 100 first ranks with BM25. Results are saved in folder ranks/.\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "LANG = \"nl\"  # or \"nl\"\n",
    "TOP_K = 100\n",
    "QUERY_PATH = f\"../baselines/preprocessed_data/queries_{LANG}_clean.csv\"\n",
    "CORPUS_PATH = f\"../baselines/preprocessed_data/corpus_{LANG}_clean.csv\"\n",
    "OUTPUT_SIMPLE = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}.json\"\n",
    "OUTPUT_DETAILED = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}_with_scores.jsonl\"\n",
    "# ------------------------\n",
    "\n",
    "os.makedirs(\"ranks\", exist_ok=True)\n",
    "\n",
    "df_corpus = pd.read_csv(CORPUS_PATH)\n",
    "corpus_texts = df_corpus[\"article\"].astype(str).tolist()\n",
    "corpus_ids = df_corpus[\"id\"].astype(str).tolist()\n",
    "tokenized_corpus = [doc.split() for doc in corpus_texts]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus, k1=1.0, b=0.6)\n",
    "\n",
    "print(f\"Loaded {len(corpus_ids)} documents.\")\n",
    "\n",
    "df_queries = pd.read_csv(QUERY_PATH)\n",
    "queries = df_queries[[\"id\", \"question\", \"article_ids\"]].astype(str).values.tolist()\n",
    "\n",
    "print(f\"Loaded {len(queries)} queries.\")\n",
    "\n",
    "ranked_results_simple = {}\n",
    "ranked_results_detailed = []\n",
    "\n",
    "for qid, question, relevant_str in tqdm(queries, desc=\"Processing queries\"):\n",
    "    query_tokens = question.split()  # already preprocessed\n",
    "\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    ranked_indices = scores.argsort()[::-1][:TOP_K]\n",
    "\n",
    "    ranked_doc_ids = [corpus_ids[i] for i in ranked_indices]\n",
    "    ranked_results_simple[qid] = ranked_doc_ids\n",
    "\n",
    "    ranked_list = [\n",
    "        {\n",
    "            \"doc_id\": corpus_ids[i],\n",
    "            \"score\": float(scores[i]),\n",
    "            \"rank\": rank + 1\n",
    "        }\n",
    "        for rank, i in enumerate(ranked_indices)\n",
    "    ]\n",
    "\n",
    "    ranked_results_detailed.append({\n",
    "        \"query_id\": qid,\n",
    "        \"relevant_ids\": [x.strip() for x in relevant_str.split(\",\")],\n",
    "        \"bm25_ranked_list\": ranked_list\n",
    "    })\n",
    "\n",
    "with open(OUTPUT_SIMPLE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ranked_results_simple, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(OUTPUT_DETAILED, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in ranked_results_detailed:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b344775",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ">>> Script for injecting relevant articles into the hard negatives. The script checks for missing relevant ids in the 100 ranks,\n",
    "for any missing article, it drops the last rank, and injects the missing id. In the end, it shuffles the lists.\n",
    "Results are saved in the folder hard_negatives/.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "LANG = \"fr\"  # or \"fr\"\n",
    "TOP_K = 100\n",
    "BM25_PATH = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}.json\"\n",
    "GOLD_PATH = f\"gold_standard_{LANG}.json\"\n",
    "OUTPUT_PATH = f\"hard_negatives/hard_negatives_{LANG}.jsonl\"\n",
    "\n",
    "os.makedirs(\"hard_negatives\", exist_ok=True)\n",
    "\n",
    "with open(BM25_PATH, encoding=\"utf-8\") as f:\n",
    "    bm25_ranks = json.load(f)\n",
    "\n",
    "with open(GOLD_PATH, encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for qid in tqdm(sorted(bm25_ranks.keys(), key=int), desc=f\"Injecting gold for {LANG.upper()}\"):\n",
    "        top100 = bm25_ranks[qid][:]\n",
    "        gold_ids = gold_data.get(qid, [])\n",
    "\n",
    "        missing = [doc_id for doc_id in gold_ids if doc_id not in top100]\n",
    "\n",
    "        if missing:\n",
    "            to_drop = []\n",
    "            i = len(top100) - 1\n",
    "            while len(to_drop) < len(missing) and i >= 0:\n",
    "                doc_id = top100[i]\n",
    "                if doc_id not in gold_ids:\n",
    "                    to_drop.append(i)\n",
    "                i -= 1\n",
    "            for index in sorted(to_drop, reverse=True):\n",
    "                del top100[index]\n",
    "            top100 += missing\n",
    "\n",
    "        assert len(top100) == TOP_K, f\"Query {qid}: {len(top100)} docs (expected {TOP_K})\"\n",
    "        assert all(doc in top100 for doc in gold_ids), f\"Query {qid}: missing relevant doc(s)\"\n",
    "\n",
    "        random.shuffle(top100)\n",
    "\n",
    "        out_f.write(json.dumps({\n",
    "            \"query_id\": qid,\n",
    "            \"candidate_docs\": top100,\n",
    "            \"relevant_ids\": gold_ids\n",
    "        }, ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_legal_document_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
