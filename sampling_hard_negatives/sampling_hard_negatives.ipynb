{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5b46afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22417 documents.\n",
      "Loaded 203 queries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 203/203 [00:03<00:00, 66.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# -------- CONFIG --------\n",
    "LANG = \"nl\"  # or \"nl\"\n",
    "TOP_K = 100\n",
    "QUERY_PATH = f\"../baselines/preprocessed_data/queries_{LANG}_clean.csv\"\n",
    "CORPUS_PATH = f\"../baselines/preprocessed_data/corpus_{LANG}_clean.csv\"\n",
    "OUTPUT_SIMPLE = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}.json\"\n",
    "OUTPUT_DETAILED = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}_with_scores.jsonl\"\n",
    "# ------------------------\n",
    "\n",
    "os.makedirs(\"ranks\", exist_ok=True)\n",
    "\n",
    "# Load corpus\n",
    "df_corpus = pd.read_csv(CORPUS_PATH)\n",
    "corpus_texts = df_corpus[\"article\"].astype(str).tolist()\n",
    "corpus_ids = df_corpus[\"id\"].astype(str).tolist()\n",
    "tokenized_corpus = [doc.split() for doc in corpus_texts]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus, k1=1.0, b=0.6)\n",
    "\n",
    "print(f\"Loaded {len(corpus_ids)} documents.\")\n",
    "\n",
    "# Load queries\n",
    "df_queries = pd.read_csv(QUERY_PATH)\n",
    "queries = df_queries[[\"id\", \"question\", \"article_ids\"]].astype(str).values.tolist()\n",
    "\n",
    "print(f\"Loaded {len(queries)} queries.\")\n",
    "\n",
    "ranked_results_simple = {}\n",
    "ranked_results_detailed = []\n",
    "\n",
    "for qid, question, relevant_str in tqdm(queries, desc=\"Processing queries\"):\n",
    "    query_tokens = question.split()  # already preprocessed\n",
    "\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    ranked_indices = scores.argsort()[::-1][:TOP_K]\n",
    "\n",
    "    ranked_doc_ids = [corpus_ids[i] for i in ranked_indices]\n",
    "    ranked_results_simple[qid] = ranked_doc_ids\n",
    "\n",
    "    ranked_list = [\n",
    "        {\n",
    "            \"doc_id\": corpus_ids[i],\n",
    "            \"score\": float(scores[i]),\n",
    "            \"rank\": rank + 1\n",
    "        }\n",
    "        for rank, i in enumerate(ranked_indices)\n",
    "    ]\n",
    "\n",
    "    ranked_results_detailed.append({\n",
    "        \"query_id\": qid,\n",
    "        \"relevant_ids\": [x.strip() for x in relevant_str.split(\",\")],\n",
    "        \"bm25_ranked_list\": ranked_list\n",
    "    })\n",
    "\n",
    "# Write output\n",
    "with open(OUTPUT_SIMPLE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ranked_results_simple, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(OUTPUT_DETAILED, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in ranked_results_detailed:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc9b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing relevant docs in top-100 ranks...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 203/203 [00:00<00:00, 101701.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 4: 1 missing relevant article(s): ['2222']\n",
      "Query 16: 6 missing relevant article(s): ['2220', '2221', '2222', '2503', '2504', '2505']\n",
      "Query 17: 5 missing relevant article(s): ['2220', '2221', '2222', '2503', '2504']\n",
      "Query 25: 2 missing relevant article(s): ['1057', '1077']\n",
      "Query 26: 1 missing relevant article(s): ['2845']\n",
      "Query 39: 2 missing relevant article(s): ['16360', '16464']\n",
      "Query 40: 1 missing relevant article(s): ['16470']\n",
      "Query 47: 1 missing relevant article(s): ['2844']\n",
      "Query 54: 3 missing relevant article(s): ['14201', '14202', '14365']\n",
      "Query 65: 2 missing relevant article(s): ['2134', '6043']\n",
      "Query 69: 1 missing relevant article(s): ['2127']\n",
      "Query 72: 3 missing relevant article(s): ['2041', '2119', '2138']\n",
      "Query 79: 5 missing relevant article(s): ['5146', '5149', '5712', '5713', '5714']\n",
      "Query 93: 2 missing relevant article(s): ['5851', '5852']\n",
      "Query 96: 1 missing relevant article(s): ['10041']\n",
      "Query 101: 6 missing relevant article(s): ['5149', '5150', '5151', '5226', '5227', '5228']\n",
      "Query 110: 1 missing relevant article(s): ['5963']\n",
      "Query 117: 3 missing relevant article(s): ['5965', '5969', '5970']\n",
      "Query 132: 2 missing relevant article(s): ['13531', '22325']\n",
      "Query 140: 1 missing relevant article(s): ['5963']\n",
      "Query 142: 4 missing relevant article(s): ['4587', '4703', '5632', '5633']\n",
      "Query 146: 4 missing relevant article(s): ['4587', '4703', '5632', '5633']\n",
      "Query 150: 1 missing relevant article(s): ['15382']\n",
      "Query 168: 1 missing relevant article(s): ['1852']\n",
      "Query 178: 1 missing relevant article(s): ['1126']\n",
      "Query 182: 2 missing relevant article(s): ['1127', '4596']\n",
      "Query 203: 2 missing relevant article(s): ['2220', '2222']\n",
      "Query 214: 2 missing relevant article(s): ['18537', '4694']\n",
      "Query 215: 1 missing relevant article(s): ['18548']\n",
      "Query 219: 1 missing relevant article(s): ['18548']\n",
      "Query 220: 2 missing relevant article(s): ['18537', '4694']\n",
      "Query 230: 1 missing relevant article(s): ['18548']\n",
      "Query 238: 3 missing relevant article(s): ['1022', '1023', '1024']\n",
      "Query 257: 1 missing relevant article(s): ['6556']\n",
      "Query 260: 2 missing relevant article(s): ['5096', '5097']\n",
      "Query 274: 1 missing relevant article(s): ['931']\n",
      "Query 275: 2 missing relevant article(s): ['1139', '4790']\n",
      "Query 281: 4 missing relevant article(s): ['1096', '1097', '1098', '931']\n",
      "Query 316: 2 missing relevant article(s): ['1055', '2844']\n",
      "Query 336: 1 missing relevant article(s): ['1055']\n",
      "Query 345: 5 missing relevant article(s): ['1060', '1064', '1065', '1066', '1067']\n",
      "Query 358: 1 missing relevant article(s): ['5963']\n",
      "Query 365: 1 missing relevant article(s): ['1384']\n",
      "Query 375: 2 missing relevant article(s): ['5123', '5150']\n",
      "Query 386: 2 missing relevant article(s): ['1367', '5414']\n",
      "Query 394: 1 missing relevant article(s): ['5411']\n",
      "Query 411: 1 missing relevant article(s): ['1676']\n",
      "Query 412: 1 missing relevant article(s): ['1676']\n",
      "Query 422: 1 missing relevant article(s): ['1071']\n",
      "Query 424: 1 missing relevant article(s): ['1071']\n",
      "Query 430: 3 missing relevant article(s): ['1274', '1275', '1276']\n",
      "Query 440: 2 missing relevant article(s): ['5466', '5468']\n",
      "Query 444: 2 missing relevant article(s): ['5483', '5484']\n",
      "Query 447: 2 missing relevant article(s): ['5483', '5484']\n",
      "Query 454: 1 missing relevant article(s): ['2248']\n",
      "Query 463: 1 missing relevant article(s): ['1073']\n",
      "Query 493: 2 missing relevant article(s): ['5468', '891']\n",
      "Query 495: 1 missing relevant article(s): ['1458']\n",
      "Query 498: 1 missing relevant article(s): ['2023']\n",
      "Query 500: 6 missing relevant article(s): ['6513', '6514', '6515', '6517', '6518', '6520']\n",
      "Query 501: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 506: 2 missing relevant article(s): ['13307', '6528']\n",
      "Query 511: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 512: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 514: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 515: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 516: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 534: 1 missing relevant article(s): ['2336']\n",
      "Query 542: 2 missing relevant article(s): ['6528', '6595']\n",
      "Query 550: 2 missing relevant article(s): ['1071', '2334']\n",
      "Query 560: 1 missing relevant article(s): ['1108']\n",
      "Query 562: 3 missing relevant article(s): ['1119', '1120', '1121']\n",
      "Query 585: 3 missing relevant article(s): ['3983', '3984', '3985']\n",
      "Query 601: 1 missing relevant article(s): ['4844']\n",
      "Query 614: 3 missing relevant article(s): ['5146', '5147', '5148']\n",
      "Query 632: 1 missing relevant article(s): ['13310']\n",
      "Query 633: 1 missing relevant article(s): ['13310']\n",
      "Query 635: 5 missing relevant article(s): ['6160', '6162', '6859', '6866', '6867']\n",
      "Query 636: 5 missing relevant article(s): ['6160', '6162', '6859', '6866', '6867']\n",
      "Query 637: 6 missing relevant article(s): ['6160', '6161', '6162', '6859', '6866', '6867']\n",
      "Query 638: 1 missing relevant article(s): ['13279']\n",
      "Query 664: 4 missing relevant article(s): ['13009', '13012', '13083', '13104']\n",
      "Query 672: 4 missing relevant article(s): ['13009', '13012', '13083', '13104']\n",
      "Query 711: 2 missing relevant article(s): ['5117', '5118']\n",
      "Query 721: 7 missing relevant article(s): ['6077', '6117', '6118', '6119', '6120', '6121', '6766']\n",
      "Query 724: 1 missing relevant article(s): ['13138']\n",
      "Query 725: 7 missing relevant article(s): ['6433', '6434', '6435', '6436', '6437', '6438', '6439']\n",
      "Query 726: 3 missing relevant article(s): ['6730', '6731', '6732']\n",
      "Query 727: 3 missing relevant article(s): ['6730', '6731', '6732']\n",
      "Query 733: 5 missing relevant article(s): ['5559', '5560', '5561', '5562', '5563']\n",
      "Query 746: 2 missing relevant article(s): ['2470', '2494']\n",
      "Query 748: 10 missing relevant article(s): ['5558', '5559', '5560', '5561', '5562', '5563', '5564', '5565', '5566', '5567']\n",
      "Query 759: 2 missing relevant article(s): ['4818', '5564']\n",
      "Query 761: 2 missing relevant article(s): ['6579', '6584']\n",
      "Query 766: 5 missing relevant article(s): ['11821', '11823', '11824', '11825', '11826']\n",
      "Query 768: 2 missing relevant article(s): ['4818', '5564']\n",
      "Query 771: 2 missing relevant article(s): ['11814', '11815']\n",
      "Query 775: 1 missing relevant article(s): ['11822']\n",
      "Query 783: 7 missing relevant article(s): ['4646', '4693', '5565', '5566', '5567', '5568', '5569']\n",
      "Query 784: 7 missing relevant article(s): ['5558', '5559', '5560', '5561', '5562', '5563', '5564']\n",
      "Query 785: 1 missing relevant article(s): ['5562']\n",
      "Query 786: 7 missing relevant article(s): ['11922', '5558', '5559', '5560', '5561', '5563', '5564']\n",
      "Query 787: 7 missing relevant article(s): ['5558', '5559', '5560', '5561', '5562', '5563', '5564']\n",
      "Query 795: 1 missing relevant article(s): ['4788']\n",
      "Query 822: 1 missing relevant article(s): ['5453']\n",
      "Query 823: 6 missing relevant article(s): ['5558', '5559', '5560', '5561', '5563', '5564']\n",
      "Query 824: 1 missing relevant article(s): ['11922']\n",
      "Query 826: 1 missing relevant article(s): ['11822']\n",
      "Query 830: 1 missing relevant article(s): ['11829']\n",
      "Query 835: 1 missing relevant article(s): ['11832']\n",
      "Query 839: 3 missing relevant article(s): ['5129', '5130', '5131']\n",
      "Query 841: 1 missing relevant article(s): ['853']\n",
      "Query 861: 5 missing relevant article(s): ['5559', '5560', '5561', '5562', '5563']\n",
      "Query 864: 8 missing relevant article(s): ['11922', '5558', '5559', '5560', '5561', '5562', '5563', '5564']\n",
      "Query 867: 1 missing relevant article(s): ['856']\n",
      "Query 873: 1 missing relevant article(s): ['849']\n",
      "Query 881: 1 missing relevant article(s): ['857']\n",
      "Query 897: 1 missing relevant article(s): ['859']\n",
      "Query 907: 2 missing relevant article(s): ['869', '870']\n",
      "Query 921: 6 missing relevant article(s): ['2220', '2221', '2222', '2503', '2504', '2505']\n",
      "Query 922: 6 missing relevant article(s): ['2023', '2220', '2221', '2222', '2503', '2504']\n",
      "Query 930: 1 missing relevant article(s): ['1490']\n",
      "Query 933: 1 missing relevant article(s): ['841']\n",
      "Query 935: 1 missing relevant article(s): ['842']\n",
      "Query 936: 2 missing relevant article(s): ['2495', '842']\n",
      "Query 939: 1 missing relevant article(s): ['842']\n",
      "Query 943: 1 missing relevant article(s): ['860']\n",
      "Query 945: 2 missing relevant article(s): ['839', '860']\n",
      "Query 961: 1 missing relevant article(s): ['860']\n",
      "Query 971: 1 missing relevant article(s): ['5824']\n",
      "Query 982: 1 missing relevant article(s): ['2507']\n",
      "Query 983: 4 missing relevant article(s): ['2506', '2507', '857', '858']\n",
      "Query 989: 1 missing relevant article(s): ['881']\n",
      "Query 995: 1 missing relevant article(s): ['842']\n",
      "Query 1001: 5 missing relevant article(s): ['611', '833', '853', '854', '873']\n",
      "Query 1002: 4 missing relevant article(s): ['873', '874', '875', '876']\n",
      "Query 1005: 4 missing relevant article(s): ['873', '874', '875', '876']\n",
      "Query 1033: 2 missing relevant article(s): ['1457', '6754']\n",
      "Query 1039: 1 missing relevant article(s): ['4694']\n",
      "Query 1040: 1 missing relevant article(s): ['4621']\n",
      "Query 1049: 2 missing relevant article(s): ['5111', '5116']\n",
      "Query 1053: 2 missing relevant article(s): ['947', '948']\n",
      "Query 1081: 1 missing relevant article(s): ['20832']\n",
      "Query 1086: 1 missing relevant article(s): ['6614']\n",
      "Query 1093: 3 missing relevant article(s): ['6461', '6614', '945']\n",
      "Query 1099: 2 missing relevant article(s): ['13049', '6238']\n",
      "Query 1103: 1 missing relevant article(s): ['22012']\n",
      "\n",
      "--- SUMMARY ---\n",
      "Total queries processed: 203\n",
      "Queries with missing relevant docs: 147\n",
      "Total missing relevant articles: 358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------- CONFIG --------\n",
    "LANG = \"nl\"  # or \"nl\"\n",
    "TOP_K = 100\n",
    "BM25_PATH = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}.json\"\n",
    "GOLD_PATH = f\"gold_standard_{LANG}.json\"\n",
    "# ------------------------\n",
    "\n",
    "# Load files\n",
    "with open(BM25_PATH, encoding=\"utf-8\") as f:\n",
    "    bm25_data = json.load(f)\n",
    "\n",
    "with open(GOLD_PATH, encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# Logging setup\n",
    "total_missing = 0\n",
    "total_queries = 0\n",
    "\n",
    "print(f\"Checking for missing relevant docs in top-{TOP_K} ranks...\\n\")\n",
    "\n",
    "for qid in tqdm(sorted(gold_data.keys(), key=int), desc=\"Processing\"):\n",
    "    relevant_ids = set(gold_data[qid])\n",
    "    top100 = set(bm25_data.get(qid, []))\n",
    "\n",
    "    missing = relevant_ids - top100\n",
    "    if missing:\n",
    "        print(f\"Query {qid}: {len(missing)} missing relevant article(s): {sorted(missing)}\")\n",
    "        total_missing += len(missing)\n",
    "    total_queries += 1\n",
    "\n",
    "print(\"\\n--- SUMMARY ---\")\n",
    "print(f\"Total queries processed: {total_queries}\")\n",
    "print(f\"Queries with missing relevant docs: {sum(1 for q in gold_data if set(gold_data[q]) - set(bm25_data.get(q, [])))}\")\n",
    "print(f\"Total missing relevant articles: {total_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c32fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adjusting ranks: 100%|██████████| 203/203 [00:00<00:00, 60886.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Adjusted ranks saved to: ranks/bm25_top100_with_drop_ranks_nl.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIG ---\n",
    "LANG = \"nl\"  # or \"fr\"\n",
    "TOP_K = 100\n",
    "INPUT_PATH = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}.json\"\n",
    "GOLD_PATH = f\"gold_standard_{LANG}.json\"\n",
    "OUTPUT_PATH = f\"ranks/bm25_top{TOP_K}_with_drop_ranks_{LANG}.json\"\n",
    "# --------------\n",
    "\n",
    "# Load BM25 top-100 ranks\n",
    "with open(INPUT_PATH, encoding=\"utf-8\") as f:\n",
    "    bm25_ranks = json.load(f)\n",
    "\n",
    "# Load gold relevant document IDs\n",
    "with open(GOLD_PATH, encoding=\"utf-8\") as f:\n",
    "    gold_relevant = json.load(f)\n",
    "\n",
    "adjusted_ranks = {}\n",
    "\n",
    "for query_id in tqdm(bm25_ranks, desc=\"Adjusting ranks\"):\n",
    "    ranked_docs = bm25_ranks[query_id]\n",
    "    gold_ids = gold_relevant.get(query_id, [])\n",
    "    \n",
    "    # Identify missing gold IDs\n",
    "    missing_gold = [doc_id for doc_id in gold_ids if doc_id not in ranked_docs]\n",
    "    \n",
    "    # Append missing gold docs at the end\n",
    "    extended_docs = ranked_docs + missing_gold\n",
    "\n",
    "    # Now remove as many docs from the end as there were missing gold IDs\n",
    "    if missing_gold:\n",
    "        to_remove = len(missing_gold)\n",
    "        new_docs = []\n",
    "        removed = 0\n",
    "        for doc_id in reversed(extended_docs):\n",
    "            if removed < to_remove and doc_id not in missing_gold:\n",
    "                removed += 1\n",
    "                continue\n",
    "            new_docs.append(doc_id)\n",
    "        final_docs = list(reversed(new_docs))\n",
    "    else:\n",
    "        final_docs = ranked_docs\n",
    "\n",
    "    adjusted_ranks[query_id] = final_docs\n",
    "\n",
    "# Save output\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(adjusted_ranks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Done. Adjusted ranks saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b344775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Injecting gold for NL: 100%|██████████| 203/203 [00:00<00:00, 5883.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Output written to: hard_negatives/hard_negatives_nl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------- CONFIG --------\n",
    "LANG = \"fr\"  # or \"fr\"\n",
    "TOP_K = 100\n",
    "BM25_PATH = f\"ranks/bm25_top{TOP_K}_ranked_results_{LANG}.json\"\n",
    "GOLD_PATH = f\"gold_standard_{LANG}.json\"\n",
    "OUTPUT_PATH = f\"hard_negatives/hard_negatives_{LANG}.jsonl\"\n",
    "# ------------------------\n",
    "\n",
    "os.makedirs(\"hard_negatives\", exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "with open(BM25_PATH, encoding=\"utf-8\") as f:\n",
    "    bm25_ranks = json.load(f)\n",
    "\n",
    "with open(GOLD_PATH, encoding=\"utf-8\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for qid in tqdm(sorted(bm25_ranks.keys(), key=int), desc=f\"Injecting gold for {LANG.upper()}\"):\n",
    "        top100 = bm25_ranks[qid][:]\n",
    "        gold_ids = gold_data.get(qid, [])\n",
    "\n",
    "        missing = [doc_id for doc_id in gold_ids if doc_id not in top100]\n",
    "\n",
    "        if missing:\n",
    "            to_drop = []\n",
    "            i = len(top100) - 1\n",
    "            while len(to_drop) < len(missing) and i >= 0:\n",
    "                doc_id = top100[i]\n",
    "                if doc_id not in gold_ids:\n",
    "                    to_drop.append(i)\n",
    "                i -= 1\n",
    "            for index in sorted(to_drop, reverse=True):\n",
    "                del top100[index]\n",
    "            top100 += missing\n",
    "\n",
    "        assert len(top100) == TOP_K, f\"Query {qid}: {len(top100)} docs (expected {TOP_K})\"\n",
    "        assert all(doc in top100 for doc in gold_ids), f\"Query {qid}: missing relevant doc(s)\"\n",
    "\n",
    "        random.shuffle(top100)\n",
    "\n",
    "        out_f.write(json.dumps({\n",
    "            \"query_id\": qid,\n",
    "            \"candidate_docs\": top100,\n",
    "            \"relevant_ids\": gold_ids\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Done. Output written to: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_legal_document_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
